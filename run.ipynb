{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "\n",
    "import torchsummary\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import plotly.express as ep\n",
    "\n",
    "from dataloader import ECGDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "LR = 1e-3\n",
    "EPOCHS = 2\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ECGDataset()\n",
    "testset = ECGDataset()\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, BATCH_SIZE,True, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, BATCH_SIZE,True, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,number_of_classes, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=12,out_channels=128,kernel_size=80,stride=64),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=128,out_channels=256,kernel_size=11,stride=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=256,out_channels=128,kernel_size=7,stride=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128,out_features=64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64,out_features=number_of_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(2)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterum = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(),LR,weight_decay=1e-5) \n",
    "optimizer = torch.optim.SGD(model.parameters(),LR*10,momentum=0.9,weight_decay=1e-5) \n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer,max_lr=LR,total_steps=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader):\n",
    "    running_acc = 0\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    with tqdm(enumerate(dataloader)) as t:\n",
    "        t.set_description_str('Train')\n",
    "        for i,(data,labels) in t:\n",
    "            # reset\n",
    "            optimizer.zero_grad(True)\n",
    "\n",
    "            # Data transfere\n",
    "            data = data.to(device,non_blocking=True).float()\n",
    "            labels = labels.to(device,non_blocking=True)\n",
    "\n",
    "            # network inference\n",
    "            target = model(data)\n",
    "\n",
    "            # loss\n",
    "            loss = criterum(target,labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # backprobagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # accuracy calculation\n",
    "            running_acc += (torch.argmax(target,-1)==labels).sum().item()\n",
    "\n",
    "            t.set_postfix({'loss':running_loss/(BATCH_SIZE*(i+1)),'acc':running_acc/(BATCH_SIZE*(i+1))})\n",
    "    return {\n",
    "        'loss':running_loss/(len(dataloader)*BATCH_SIZE),\n",
    "        'acc':running_acc/(len(dataloader)*BATCH_SIZE),\n",
    "        }\n",
    "\n",
    "def test(model, dataloader):\n",
    "    running_acc = 0\n",
    "    running_loss = 0\n",
    "    model.eval()\n",
    "    with tqdm(enumerate(dataloader)) as t:\n",
    "        t.set_description_str('Test ')\n",
    "        for i,(data,labels) in t:\n",
    "            # Data transfere\n",
    "            data = data.to(device,non_blocking=True).float()\n",
    "            labels = labels.to(device,non_blocking=True)\n",
    "\n",
    "            # network inference\n",
    "            target = model(data)\n",
    "\n",
    "            # loss\n",
    "            loss = criterum(target,labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # accuracy calculation\n",
    "            running_acc += (torch.argmax(target,-1)==labels).sum().item()\n",
    "\n",
    "            t.set_postfix({'loss':running_loss/(BATCH_SIZE*(i+1)),'acc':running_acc/(BATCH_SIZE*(i+1))})\n",
    "    return {\n",
    "        'loss':running_loss/(len(dataloader)*BATCH_SIZE),\n",
    "        'acc':running_acc/(len(dataloader)*BATCH_SIZE),\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "\n",
    "best_test = 0\n",
    "best_model = None\n",
    "for i in range(EPOCHS):\n",
    "    train_dict = train(model,trainloader)\n",
    "    test_dict = test(model,testloader)\n",
    "\n",
    "    train_dict = dict([('Train_'+key,value) for key,value in train_dict.items()])\n",
    "    test_dict = dict([('Test_'+key,value) for key,value in test_dict.items()])\n",
    "\n",
    "\n",
    "    stats.append(train_dict|test_dict|{'Epoch':i,'LR':lr_scheduler.get_lr()[0]})\n",
    "    if test_dict['Test_acc']>best_test:\n",
    "        best_test = test_dict['Test_acc']\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "    lr_scheduler.step()\n",
    "stats = pd.DataFrame(stats)\n",
    "stats.to_csv('train_progress.csv')\n",
    "\n",
    "torch.save(best_model.state_dict(),'best_model_state_dict.pt')\n",
    "torch.save(best_model,'best_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model_load = Network(2)\n",
    "best_model_load.load_state_dict(torch.load('best_model_state_dict.pt')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchsummary.summary(model,(12,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ep.line(stats,x='Epoch',y=['Train_loss','Test_loss'])\n",
    "fig.show()\n",
    "fig.write_html('./tmp.html')\n",
    "fig=ep.line(stats,x='Epoch',y=['Train_acc','Test_acc'])\n",
    "fig.show()\n",
    "fig=ep.line(stats,x='Epoch',y=['LR'])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
